---
title: "K Nearest Neighbors - KNN"
output: 
  html_document:
    code_folding: hide
---
A continuación aplicaremos un modelo knn o k nearest neighbors a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según tenga "k" vecinos más cerca de un grupo o de otro. Es decir, calcula la distancia del elemento nuevo a cada uno de los existentes, y ordena dichas distancias de menor a mayor para ir seleccionando el grupo al que pertenece. Este grupo será, por tanto, el de mayor frecuencia con menores distancias.

El knn es un algoritmo de aprendizaje supervisado, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas.

Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test:

```{r message = FALSE}
library(class)
library(dplyr)
library(caret)
library (ROCR)
library(MASS)
library(hmeasure)
source("funcs.R")
data(Pima.te) 

```

```{r load_data, message=FALSE, warning=FALSE, echo=TRUE}

dataTrain_origin <- readRDS("datasetTrain.rds")
dataTest_origin <- readRDS("datasetTest.rds")

```

Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.

Nuestro modelo clasificará casas entre estos dos grupos.

```{r}

dataTrain <- dataTrain_origin %>% dplyr::select(-SalePrice)
dataTest <- dataTest_origin %>% dplyr::select(-SalePrice)

```

Para este modelo se han elegido un grupo de caracteristica del dataset original. Son todas de numéricas y se han escogido debido a un analisis exploratorio de los datos previos y la realización de un modelo de randon forest que se explicara en otra sección del informe.

A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test.

```{r}
#group <- c('GrLivArea','LotArea','TotalSF','MSSubClass','Neighborhood','BedroomAbvGr','BldgType','OverallCond','TotalBsmtSF', 'GrupoPrecio')
group <- c('GrLivArea','LotArea','TotalSF','ExterQual','KitchenQual', 'GrupoPrecio')
remove <- c('GrupoPrecio')
col_to_factor <- colnames(dataTrain) [! colnames(dataTrain) %in% remove]

dataTrain <- dataTrain %>% dplyr::select(group)
dataTest <- dataTest %>% dplyr::select(group)

dataTrain <- dataTrain %>% as_factor_all(col_to_factor)
dataTest <- dataTest %>% as_factor_all(col_to_factor)

```

```{r}

XTrain <- dataTrain %>% dplyr::select(-GrupoPrecio)
YTrain <- dataTrain$GrupoPrecio

XTest <- dataTest %>% dplyr::select(-GrupoPrecio)
YTest <- dataTest$GrupoPrecio

```

```{r}

proccess <- preProcess(x = XTrain, method = c("center", "scale"))

#proccess <- preProcess(x = XTrain, method = c("range"))

transformed <- predict(proccess, XTest)

(proccess)
##TRAIN
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3)
knn <- train(GrupoPrecio ~ ., data = dataTrain, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
#knn <- train(GrupoPrecio ~ ., data = dataTrain, method = "knn", trControl = ctrl, preProcess = c("range"), tuneLength = 20)
knn

plot(knn)



knnPredict <- predict(knn,newdata = XTest )

confusionMatrix(knnPredict, YTest, mode = "prec_recall" ) ### ME gustaa

mean(knnPredict == YTest)
```

```{r}
###########################################################

ctrl <- trainControl(method="repeatedcv",repeats = 3,classProbs=TRUE,summaryFunction = twoClassSummary)
knnFit <- train(GrupoPrecio ~ ., data = dataTrain, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
knnFit

plot(knnFit, print.thres = 0.5, type="S")

knnPredict <- predict(knnFit,newdata = dataTest )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, YTest )

```

```{r}
##########################################################
library(pROC)
knnPredict <- predict(knnFit, newdata = dataTest , type="prob")

knnPredict
rev(YTest)
knnROC <- roc(YTest, knnPredict[,"Caro"], levels = c("Barato","Caro"))
knnROC

plot(knnROC, type="S", print.thres = 0.5)

```





-----------------------------------------------------------------------------
Inciamos el modelo entrenado con el conjunto de entrenamiento y evaluando como se comporta con el mismo. Si los grupos estan bien separados con una k mayor que uno deberia de dar un porcentaje de acierto alto, porque se evalua contra el mismo conjutno que usamos para entrenar el modelo.


```{r}

model <- knn(XTrain, XTrain, cl = YTrain, k=3)

```

```{r }

tab_train <- table(model, YTrain, dnn = c("Actual", "Predichos"))
(tab_train)
accuracy(tab_train)
knn_train_error <- calc_error_rate(predicted.value=model, true.value=YTrain)
(knn_train_error)
draw_confusion_matrix(tab_train, "Actual", "Predichos")
cm <- confusionMatrix(tab_train)
(cm)

```

Podemos observar que al acierto es alto pero no como deberia ya que intenta clasificar los mismos elementos que se usaron para entrenar. Esto muestra que posiblemente se tengan que volver a escoger un grupo de caracteristicas diferentes.

Procedemos a evaluar el modelo con nuestro conjunto de test y buscar el valor de k más optimo.

```{r}

model <- knn(XTrain, XTest, cl = YTrain, k=3)

```

```{r }

tab_test <- table(model, YTest, dnn = c("Actual", "Predichos"))
(tab_test)
accuracy(tab_test)
knn_test_error <- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_error)
draw_confusion_matrix(tab_test, "Actual", "Predichos")
cm <- confusionMatrix(tab_test)
(cm)

```

Obtemos el hiperparametro k (el numero de vecinos que determinaran la clase que predice el modelo), probando una series de valores y evaluando cual da un % de acierto mayor.

```{r }
i <- 1
k <- 1

for(i in 1:100){
  model <- knn(XTrain, XTest, cl = YTrain, k=i)
  tab_test <- table(model, YTest, dnn = c("Actual", "Predichos"))
  k[i] <- accuracy(tab_test)
  opt <- i
  cat(opt, '=', k[i], '')
}
plot(k, type="b", xlab="K-Value", ylab="Accuracy level")
```
Una vez obtenida la k más optima, evaluamos al modelo con el conjunto de test y con el valor de k que hemos obtenido. El modelo deberia de funcionar algo mejor.

```{r}

model <- knn(XTrain, XTest, cl = YTrain, k=11)

saveRDS(model, "modelKNN.rds")
```

```{r }

tab_test_h <- table(model, YTest, dnn = c("Actual", "Predichos"))

(tab_test_h)
draw_confusion_matrix(tab_test_h, "Actual", "Predichos")

accuracy(tab_test_h)
knn_test_h_error <- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_h_error)
cm <- confusionMatrix(tab_test_h)
(cm)
```
