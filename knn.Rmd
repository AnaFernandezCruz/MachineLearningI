---
title: "K Nearest Neighbors - KNN"
---


```{r load_libraries}
library(class)
library(dplyr)
library(caret)
library (ROCR)
source("funcs.R")

```

Cargamos los datos que utilizaremos para el entrenamiento, el test y la validación:

```{r load_data, message=FALSE, warning=FALSE, echo=TRUE}

dataTrain <- readRDS("datasetTrain.csv")
dataTest <- readRDS("datasetTest.csv")

dataValidation <- readRDS("datasetValidation.csv")

```

Procedemos a despejar de los dataset la variable objetivo original SalePrice. De la cual creamos la variable GrupoPrecio, del tipo categorica.

```{r choose_features}

dataTrain <- dataTrain %>% dplyr::select(-SalePrice)
dataTest <- dataTest %>% dplyr::select(-SalePrice)

dataValidation <- dataValidation %>% dplyr::select(-SalePrice)

group <- c('TotalSF','LotArea','GrLivArea','GrupoPrecio')

dataTrain <- dataTrain %>% dplyr::select(group)
dataTest <- dataTest %>% dplyr::select(group)

dataValidation <- dataValidation %>% dplyr::select(group)

```

A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test y finalmente con el grupo de validación.

```{r process_data }

XTrain <- dataTrain %>% dplyr::select(-GrupoPrecio)
YTrain <- dataTrain$GrupoPrecio

XTest <- dataTest %>% dplyr::select(-GrupoPrecio)
YTest <- dataTest$GrupoPrecio

XValidation <- dataValidation %>% dplyr::select(-GrupoPrecio)
YValidation <- dataValidation$GrupoPrecio

```


```{r run_model}

model <- knn(XTrain, XTest, cl = YTrain, k=1)

```

```{r }

tab_test <- table(model, YTest, dnn = c("Actual", "Predichos"))

(tab_test)

accuracy(tab_test)
knn_test_error <- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_error)

draw_confusion_matrix(tab_test, "Actual", "Predichos")
```

```{r }

cm <- confusionMatrix(tab_test)
(cm)
```

Obtemos el hiperparametro k (el numero de vecinos que determinaran la clase que predice el modelo), probando una series de valores y evaluando cual da una accuary mayor.

```{r }
i <- 1
k <- 1

for(i in 1:28){
  model <- knn(XTrain, XTest, cl = YTrain, k=i)
  tab_test <- table(model, YTest, dnn = c("Actual", "Predichos"))
  k[i] <- accuracy(tab_test)
  opt <- i
  cat(opt, '=', k[i], '')
}
plot(k, type="b", xlab="K-Value", ylab="Accuracy level")
(k)
```
Una vez obtenida la k más optima podemos ver que el modelo funciona mejor.

```{r}

model <- knn(XTrain, XTest, cl = YTrain, k=13)

```

```{r }

tab_test <- table(model, YTest, dnn = c("Actual", "Predichos"))

(tab_test)
draw_confusion_matrix(tab_test, "Actual", "Predichos")

accuracy(tab_test)
knn_test_error <- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_error)
cm <- confusionMatrix(tab_test)
(cm)
```

Utilizamos el conjunto de validación para comprobar nuestro modelo.

```{r}

model <- knn(XTrain, XValidation, cl = YTrain, k=13)

```

```{r }

tab_validation <- table(model, YValidation, dnn = c("Actual", "Predichos"))

(tab_validation)
draw_confusion_matrix(tab_validation, "Actual", "Predichos")

accuracy(tab_validation)
knn_validation_error <- calc_error_rate(predicted.value=model, true.value=YValidation)
(knn_validation_error)
cm <- confusionMatrix(tab_validation)
(cm)

```
