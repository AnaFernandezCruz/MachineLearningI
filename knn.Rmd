---
title: "K Nearest Neighbors - KNN"
output: 
  html_document:
    code_folding: hide
---
A continuación aplicaremos un modelo knn o k nearest neighbors a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según tenga "k" vecinos más cerca de un grupo o de otro. Es decir, calcula la distancia del elemento nuevo a cada uno de los existentes, y ordena dichas distancias de menor a mayor para ir seleccionando el grupo al que pertenece. Este grupo será, por tanto, el de mayor frecuencia con menores distancias.

El knn es un algoritmo de aprendizaje supervisado, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas.

Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test:

```{r message = FALSE}
library(class)
library(dplyr)
library(caret)
library (ROCR)
library(MASS)
library(hmeasure)
library(data.table)
source("funcs.R")
data(Pima.te) 

```

```{r load_data, message=FALSE, warning=FALSE, echo=TRUE}

dataTrain_origin <- readRDS("datasetTrainModeloClasificador.rds")
dataTest_origin <- readRDS("datasetTestModeloClasificador.rds")


dataTrain_origin_PCA <- readRDS("datasetTrainModeloClasificadorPCA.rds")
dataTest_origin_PCA <- readRDS("datasetTestModeloClasificadorPCA.rds")

coordenadasPCATrain <- as.data.table(cbind(dataTrain_origin_PCA$ind$coord, SalePrice= dataTrain_origin %>% dplyr::select(c("SalePrice"))  ))

```

Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.

Nuestro modelo clasificará casas entre estos dos grupos.

```{r}

dataTrain <- dataTrain_origin %>% dplyr::select(-SalePrice)
dataTest <- dataTest_origin %>% dplyr::select(-SalePrice)

```

Para este modelo se han elegido un grupo de caracteristica del dataset original. Se han escogido debido a un analisis previo del conjunto de datos en el que mediante un modelo random forest se ha determinado el grupo de caracteristicas más importantes. A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test. Debido a que nuestros datos tiene variables categoricas, tenemos que transformarlas a numericas para el modelo knn.

```{r}

remove <- c('GrupoPrecio')
col_to_factor <- colnames(dataTrain) [! colnames(dataTrain) %in% remove]

dataTrain <- dataTrain %>% as_factor_all(col_to_factor)
dataTest <- dataTest %>% as_factor_all(col_to_factor)

XTrain <- dataTrain %>% dplyr::select(-GrupoPrecio)
YTrain <- dataTrain$GrupoPrecio

XTest <- dataTest %>% dplyr::select(-GrupoPrecio)
YTest <- dataTest$GrupoPrecio

```

Entrenamos el modelo a la vez que buscamos el k más optimo para el conjunto de datos de train normalizados.

```{r}
#Normalización
ctrNorm <- preProcess(x = XTrain, method = c("center", "scale"))

dataTrainNorm <- predict(ctrNorm, dataTrain)

#Entrenamiento y busqueda de k más optimo
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3)
knn <- train(GrupoPrecio ~ ., data = dataTrainNorm, method = "knn", trControl = ctrl, tuneLength = 20)

plot(knn)
```

A continuación evaluamos nuestro modelo con el conjunto de test normalizados con la información de train.

```{r}
#Normalizamos con la información de train.
XTestNorm <- predict(ctrNorm, XTest)

pred <- predict(knn, newdata = XTestNorm )

cm <- confusionMatrix(pred, YTest, mode = "prec_recall" )

mean(pred == YTest)

(cm)


```


```{r}
tab_test <- table(pred, YTest, dnn = c("Actual", "Predichos"))
draw_confusion_matrix(tab_test, "Actual", "Predichos")
```

APLICAMOS PCA
```{r}

```




-----------------------------------------------------------------------------------
```{r}
###########################################################

ctrl <- trainControl(method="repeatedcv",repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary)
knnFit <- train(GrupoPrecio ~ ., data = dataTrain, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
knnFit

plot(knnFit, print.thres = 0.5, type="S")

knnPredict <- predict(knnFit,newdata = dataTest )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, YTest )

```

```{r}
##########################################################
library(pROC)
knnPredict <- predict(knnFit, newdata = dataTest , type="prob")




data(aSAH)

knnPredict
a <- rev(YTest)
(a)
knnROC <- roc(YTest, knnPredict[,"Caro"], levels = c("Barato","Caro"))
#knnROC

ROC <- roc(YTest, knnPredict[,"Caro"], levels = c("Barato","Caro"), ret = c("roc", "coords", "all_coords"))
(ROC)

plot(ROC, type="S", print.thres = 0.5)
plot(knnROC, type="S", print.thres = 0.5)


roc1 <- roc(YTest, knnPredict[,"Caro"], percent=TRUE,
            # arguments for auc
            partial.auc = c(100, 90), partial.auc.correct=TRUE,
            partial.auc.focus = "sens",
            # arguments for ci
            ci = TRUE, boot.n = 100, ci.alpha = 0.9, stratified = FALSE,
            # arguments for plot
            plot = TRUE, auc.polygon = TRUE, max.auc.polygon = TRUE, grid = TRUE,
            print.auc = TRUE, show.thres = TRUE)

coords(roc1, "best", ret=c("threshold", "specificity", "1-npv"))

```

-----------------------------------------------------------------------------