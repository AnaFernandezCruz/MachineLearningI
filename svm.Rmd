---
title: "SVM"
output: 
  html_document:
    code_folding: hide
---

A continuación aplicaremos un modelo svm o support vector machine a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según como consiga crear hiperplanos que separen de manera lineal los grupos de datos.

Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test:

```{r message = FALSE}
library(class)
library(dplyr)
library(caret)
library (ROCR)
library(e1071)
source("funcs.R")
```


```{r load_data, message=FALSE, warning=FALSE, echo=TRUE}

dataTrain_origin <- readRDS("datasetTrain.rds")
dataTest_origin <- readRDS("datasetTest.rds")

```

Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.

Nuestro modelo clasificará casas entre estos dos grupos.

```{r}

dataTrain <- dataTrain_origin %>% dplyr::select(-SalePrice)
dataTest <- dataTest_origin %>% dplyr::select(-SalePrice)

```

Para este modelo se han escogido dos grupos de caracteristicas, para poder comproba como mejora si añadimos o quitamos variables al modelo. Estos dos grupos de caracteristicas las divideramos en group1 y group2.

```{r}

group <- c('GrLivArea','LotArea','TotalSF','ExterQual','KitchenQual', 'GrupoPrecio')
remove <- c('GrupoPrecio')
col_to_factor <- colnames(dataTrain) [! colnames(dataTrain) %in% remove]

dataTrain <- dataTrain %>% dplyr::select(group)
dataTest <- dataTest %>% dplyr::select(group)

dataTrain <- dataTrain %>% as_factor_all(col_to_factor)
dataTest <- dataTest %>% as_factor_all(col_to_factor)
```


```{r}

XTrain <- dataTrain %>% dplyr::select(-GrupoPrecio)
YTrain <- dataTrain$GrupoPrecio

XTest <- dataTest %>% dplyr::select(-GrupoPrecio)
YTest <- dataTest$GrupoPrecio

```

```{r}
svmfit = svm(GrupoPrecio ~ ., data = dataTrain, kernel = "linear", cost = 10, scale = FALSE)
(svmfit$index)
summary(svmfit)

svmfit_ajust = svm(GrupoPrecio ~ ., data = dataTrain, kernel = "linear", cost = 0.1, scale = FALSE)
(svmfit_ajust$index)
summary(svmfit_ajust)


tune.out = tune(svm, GrupoPrecio ~ ., data = dataTrain, kernel = "linear", ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
(tune.out$index)
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)


```

```{r}
ypred <- predict(bestmod, dataTest)
table(predict = ypred, truth = YTest)

```








-------------------------------------------------------------------------------------------------------
A continuación, entrenamos el modelo con el conjunto de entrenamiento y evaluamos con el conjunto de test, el primer grupo de caracteristicas escogidas (group1).

```{r run_model}

#model <- svm(formula = GrupoPrecio ~ ., data = dataTrain, kernel = "linear", cost = 1, scale = TRUE)
svm <- best.tune(method = svm, train.x = GrupoPrecio ~ ., data = dataTrain, ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), kernel = "linear")
#svm <- best.tune(method = svm, train.x = GrupoPrecio ~ ., data = dataTrain, ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), kernel = "radial", gamma = 1)

```

Debido a que este grupo solo contiene dos caracteristicas nos permite dibujar como el modelo svm divide el plano para clasificar los nuevos registros. Visualizamos también como se comporta el modelo con el conjunto de datos de test.

```{r}

pred <- predict(svm, newdata = XTest)
tab_test <- table(pred, YTest, dnn = c("Actual", "Predichos"))
(tab_test)
draw_confusion_matrix(tab_test, "Actual", "Predichos")

accuracy(tab_test)
svm_test_error <- calc_error_rate(predicted.value=pred, true.value=YTest)
(svm_test_error)

cm1 <- confusionMatrix(tab_test)
(cm1)
```

A continuación se realizara todos los pasos anteriores pero esta vez con otro conjunto de caracteristicas. Este conjunto dispone de más caracteristicas por lo que no podremos visualizar como separa el plano de caracteristicas. 
Podremos ver cuales de los dos modelos SVM funciona mejor.

```{r}

model2 <- best.tune(method = svm, train.x = GrupoPrecio ~ ., data = dataTrain2, ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), kernel = "radial", gamma = 1)

saveRDS(model, "model2SVM.rds")
```

```{r}
pred2 <- predict(model2, newdata = XTest2)
tab_test2 <- table(pred2, YTest2, dnn = c("Actual", "Predichos"))
(tab_test2)
draw_confusion_matrix(tab_test2, "Actual", "Predichos")

accuracy(tab_test2)
svm_test_error2 <- calc_error_rate(predicted.value=pred2, true.value=YTest2)
(svm_test_error2)

cm2 <- confusionMatrix(tab_test2)
(cm2)
```



