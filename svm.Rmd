---
title: "SVM"
output: html_document
---

A continuación aplicaremos un modelo svm o support vector machine a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según como consiga crear hiperplanos que separen de manera lineal los grupos de datos.

Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test:

```{r message = FALSE}
library(class)
library(dplyr)
library(caret)
library (ROCR)
library(kernlab)
library(data.table)
library(MLeval)
library(DMwR)
source("funcs.R")

```


```{r load_data, message=FALSE, warning=FALSE, echo=TRUE}

dataTrain_origin <- readRDS("datasetTrainModeloClasificador.rds")
dataTest_origin <- readRDS("datasetTestModeloClasificador.rds")

```

Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.

Nuestro modelo clasificará casas entre estos dos grupos.

```{r}

dataTrain <- dataTrain_origin %>% dplyr::select(-SalePrice)
dataTest <- dataTest_origin %>% dplyr::select(-SalePrice)

```

Para este modelo se han escogido dos grupos de caracteristicas, para poder comproba como mejora si añadimos o quitamos variables al modelo. Estos dos grupos de caracteristicas las divideramos en group1 y group2.

```{r}

remove <- c('GrupoPrecio')
col_to_factor <- colnames(dataTrain) [! colnames(dataTrain) %in% remove]

dataTrain <- dataTrain %>% as_factor_all(col_to_factor)
dataTest <- dataTest %>% as_factor_all(col_to_factor)

XTrain <- dataTrain %>% dplyr::select(-GrupoPrecio)
YTrain <- dataTrain$GrupoPrecio

XTest <- dataTest %>% dplyr::select(-GrupoPrecio)
YTest <- dataTest$GrupoPrecio

```

### ENTRENAMIENTO, OPTIMIZACIÓN Y EVALUACIÓN DEL MODELO

Entrenamos el modelo a la vez que buscamos los hiperparametros más optimos. Se hace un pre entreno para conseguir esos hiperparametros, una vez tengamos una aproximación inicial, volveremos a entrenar ofreciendole al modelo una serie de posibles valores optimos cercanos a la aproximación incial. Con esto se puede observar que el modelo mejora ligeramente.

```{r}
set.seed(400)
#Normalización
ctrNorm <- preProcess(x = XTrain, method = c("center", "scale"))

dataTrainNorm <- predict(ctrNorm, dataTrain)

#Entrenamiento y busqueda de k más optimo

ctrl <-  trainControl("repeatedcv", repeats=3,classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE, sampling = "smote")
svm <- train(GrupoPrecio ~ ., data = dataTrainNorm, method = "svmRadial", trControl = ctrl, tuneLength = 20)
(svm)
plot(svm)

```

```{r}
set.seed(400)
grid <- expand.grid(sigma = c(.029, .03, .031), C = c(0.15, 0.20, 0.25, 0.5, 0.75))

svm <- train(GrupoPrecio ~ ., data = dataTrainNorm, method = "svmRadial", trControl = ctrl, tuneGrid = grid)
(svm)
plot(svm)

XTestNorm <- predict(ctrNorm, XTest)
pred <- predict(svm, newdata = XTestNorm )
cm <- confusionMatrix(pred, YTest, mode = "prec_recall" )
(cm)
tab_test <- table(pred, YTest, dnn = c("Actual", "Predichos"))
draw_confusion_matrix(tab_test, "Actual", "Predichos")
```
##### APLICAMOS PCA

```{r}
set.seed(400)
dataTrain_origin_PCA <- readRDS("datasetTrainModeloClasificadorPCA.rds")
dataTest_origin_PCA <- readRDS("datasetTestModeloClasificadorPCA.rds")

PCATrain <- as.data.table(cbind(dataTrain_origin_PCA$ind$coord, GrupoPrecio = dataTrain_origin %>% dplyr::select(c("GrupoPrecio"))))
PCATest <- as.data.table(cbind(dataTest_origin_PCA$ind$coord, GrupoPrecio = dataTest_origin %>% dplyr::select(c("GrupoPrecio"))))

XPCATrain <- PCATrain %>% dplyr::select(-GrupoPrecio)
YPCATrain <- PCATrain$GrupoPrecio
XPCATest <- PCATest %>% dplyr::select(-GrupoPrecio)
YPCATest <- PCATest$GrupoPrecio


ctrl <-  trainControl("repeatedcv", repeats=3,classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE, sampling = "smote")

svm_pca <- train(GrupoPrecio ~ ., data = PCATrain, method = "svmRadial", trControl = ctrl, metric="ROC", tuneLength = 20)
(svm_pca)
plot(svm_pca)

```

```{r}
set.seed(400)
grid <- expand.grid(sigma = c(.015, .016, 0.17), C = c(1.75, 1.9, 2, 2.1, 2.25))

svm_pca <- train(GrupoPrecio ~ ., data = PCATrain, method = "svmRadial", trControl = ctrl, metric="ROC", tuneGrid = grid)
(svm_pca)
plot(svm_pca)

pred_pca <- predict(svm_pca, newdata = XPCATest)

cm_pca <- confusionMatrix(pred_pca, YPCATest, mode = "prec_recall" )
(cm_pca)
tab_test_pca <- table(pred_pca, YPCATest, dnn = c("Actual", "Predichos"))
draw_confusion_matrix(tab_test_pca, "Actual", "Predichos")

```

### EVALUACIÓN

```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18, multi.col=T}
res <-evalm(list(svm_pca,svm),gnames = c('svm_pca','svm'),rlinethick=0.8,fsize=30, showplots = TRUE , bins=20, plots = c("prg"))

```

```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18, multi.col=T}
res <-evalm(list(svm_pca,svm),gnames = c('svm_pca','svm'),rlinethick=0.8,fsize=30, showplots = TRUE , bins=20, plots = c("pr"))

```

```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18, multi.col=T}
res <-evalm(list(svm_pca,svm),gnames = c('svm_pca','svm'),rlinethick=0.8,fsize=30, showplots = TRUE , bins=20, plots = c("r"))

```

```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18, multi.col=T}
res <-evalm(list(svm_pca,svm),gnames = c('svm_pca','svm'),rlinethick=0.8,fsize=30, showplots = TRUE , bins=20, plots = c("cc"))

```


```{r , message=FALSE, warning=FALSE, echo=TRUE}

saveRDS(svm, "svm.rds")
saveRDS(svm_pca, "svm_pca.rds")

```

