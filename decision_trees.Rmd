---
title: "DECISION TREES"
output: 
  html_document:
    code_folding: hide
---

En este punto vamos a aplicar los árboles de decisión a nuestro modelo. Los árboles de decisión se componen del nodo raíz, que es del que partes, y respondiendo preguntas con "si" o "no", nos iremos moviendo por los nodos interiores hasta llegar a las hojas o nodos terminales. Nuestro objetivo es tener un árbol de decisión que use el menor número de preguntas posible.

Para empezar, cargamos nuestros datos. Los datos que vamos a utilizar es el dataframe antes de pasarlo por PCA. Esto es debido a que el fuerte del árbol de decisión es la explicatividad del mismo y el poder ver gráficamente las elecciones que va haciendo, como si fuera el quién es quién. Si lo hacemos con las dimensiones nuevas que nos proporciona el PCA perderíamos esta utilidad de los árboles de decisión ya que las dimensiones que nos proporciona el PCA no tienen sentido a nuestros ojos.

```{r message = FALSE}
library(class)
library(dplyr)
library(caret)
library (ROCR)
library(MASS)
library(DMwR)
library(hmeasure)
library(data.table)
library(rpart)
dataTrain <- readRDS("datasetTrainModeloClasificador.rds") 
myvars <- names(dataTrain) %in% c('SalePrice')
dataTrain <- dataTrain[!myvars]

dataTest <- readRDS("datasetTestModeloClasificador.rds")
myvars <- names(dataTest) %in% c('SalePrice')
dataTest <- dataTest[!myvars]

set.seed(123)
```

Definimos el árbol de decisión: para ello, como no conocemos ninguna relación con el resto de variables, no escribiremos ninguna fórmula. El árbol de decisiones lo vamos a entrenar usando la librería Caret.
Caret proporciona una herramienta que se llama trainControl, la cual controla los matices computacionales de la función train.

```{r message = FALSE, warning=FALSE}

house.tree1 <- train(
                    x = dataTrain[, names(dataTrain) != "GrupoPrecio"],
                    y = dataTrain$GrupoPrecio,
                    method = "rpart",
                    parms = list(split = "information"),
                    trControl = trainControl(search = "random",
                                             method = "cv",
                                             classProbs = TRUE, 
                                             summaryFunction = twoClassSummary,
                                             savePredictions = TRUE,
                                             sampling = "smote")
                    )

house.tree1
```
Si nos fijamos en el resultado que obtenemos cuando hacemos un print del árbol, vemos que nos CARET nos da información sobre el valor CP o Complexity Parameter. Este parámetro de complejidad se utilizaría en otras bibliotecas para decidir en que punto podar o no el árbol, pero hemos decidido usar CARET puesto que cuando ejecutas el código para generar el modelo ya evalúa los distintos valores de CP y se queda con un valor u otro para que tu modelo ya esté optimizado y no tengas que hacer nada más. En este caso, el valor del parámetro de complejidad ha sido elegido en función del valor de la curva ROC como bien nos informa la biblioteca.

El árbol estará más podado conforme el parámetro de complejidad sea más pequeño, por lo que en nuestro la biblioteca ha decidido quedarse con un árbol menos podado pero que nos da mayor porcentaje de accuracy (o acierto) en nuestro modelo.


```{r message = FALSE, warning=FALSE}
library(rattle)
fancyRpartPlot(house.tree1$finalModel)
```

Podemos observar como los tipos de casas se han ido dividiendo según las decisiones tomadas en cada uno de los nodos del árbol. También podemos ver como en los nodos terminales aparece la distribución de la variable GrupoPrecios, así que podemos hacer una estimación del error de clasficación del árbol con las herramientas vistas en clase. Para ello:

```{r message = FALSE, warning=FALSE}
##MATRIZ CONFUSION
house.pred <- predict(house.tree1, newdata = dataTest)
table1 <- table(house.pred, dataTest$GrupoPrecio)
table1


cm_nopca <- confusionMatrix(house.pred, dataTest$GrupoPrecio, mode = "prec_recall" )
cm_nopca

##CÁLCULO DEL ERROR
error.rate_nopca = mean(house.pred != dataTest$GrupoPrecio)
error.rate_nopca
```

Como hemos dicho anteriormente, uno de los principales beneficios de los árboles de decisión es la explicatividad que tienen. Si usamos las transformaciones proporcionadas del análisis del PCA existe la posibilidad de que el modelo mejor y perdamos esa explicatividad: vamos a comprobarlo.

Cargamos los datos:

```{r}
dataTrain_origin_PCA <- readRDS("datasetTrainModeloClasificadorPCA.rds")
dataTest_origin_PCA <- readRDS("datasetTestModeloClasificadorPCA.rds") 

PCATrain <- as.data.table(cbind(dataTrain_origin_PCA$ind$coord, GrupoPrecio = dataTrain %>% dplyr::select(c("GrupoPrecio"))))
PCATest <- as.data.table(cbind(dataTest_origin_PCA$ind$coord, GrupoPrecio = dataTest %>% dplyr::select(c("GrupoPrecio"))))

XPCATrain <- PCATrain %>% dplyr::select(-GrupoPrecio)
YPCATrain <- PCATrain$GrupoPrecio
XPCATest <- PCATest %>% dplyr::select(-GrupoPrecio)
YPCATest <- PCATest$GrupoPrecio
```

Entrenamos el modelo:

```{r message = FALSE, warning=FALSE}
house.tree_pca <- train(
                    x = XPCATrain,
                    y = YPCATrain,
                    method = "rpart",
                    parms = list(split = "information"),
                    trControl = trainControl(search = "random",
                                             method = "cv",
                                             classProbs = TRUE, 
                                             summaryFunction = twoClassSummary,
                                             savePredictions = TRUE,
                                             sampling = "smote")
                    )

house.tree_pca
```

Podemos ver cuando dibujamos el árbol que las variables no tienen ningún sentido para nosotros.

```{r message = FALSE, warning=FALSE}
library(rattle)
fancyRpartPlot(house.tree_pca$finalModel)
```

```{r message = FALSE, warning=FALSE}
##MATRIZ CONFUSION
house.pred_pca <- predict(house.tree_pca, newdata = XPCATest)
table_pca <- table(house.pred_pca, YPCATest)
table_pca


cm_pca <- confusionMatrix(house.pred_pca, YPCATest,mode = "prec_recall")
cm_pca

##CÁLCULO DEL ERROR
error.rate_pca = mean(house.pred_pca !=YPCATest)
error.rate_pca
```

- CURVA ROC.

Si comparamos ambos modelos: variables originales o variables producto del PCA usando la curva ROC y sus matrices de confusión + errores, tenemos:

```{r}
cm_nopca
error.rate_nopca

print('__________________')

cm_pca
error.rate_pca

```

Lo que vemos es que sale mejor modelo cuando no utilizamos pca y dejamos las variables que a ojo del ciéntifico de datos podemos entender mejor. 
Además la matriz de confusión nos indica que predecimos mejor usando el modelo sin pca, aunque el valor de f1 sea mejor para el segundo modelo.

```{r , message=FALSE, warning=FALSE, echo=TRUE}
res <- evalm(list(house.tree1,house.tree_pca),gnames = c('house.tree_nopca','house.tree_pca'))
```
Aunque con la curva ROC vemos que, efectivamente, son bastante similares. Así que preferiremos usar el modelo sin PCA porque así podemos seguir usando la característica de explicatividad que tienen este tipo de modelos.

```{r}
saveRDS(house.tree1, "house_tree_nopca.rds")
saveRDS(house.tree_pca, "house_tree_pca.rds")
```

