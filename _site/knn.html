<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>K Nearest Neighbors - KNN</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ML</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Cluster.html">Clustering</a>
</li>
<li>
  <a href="PCA.html">PCA</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Aprendizaje supervisado
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="glm.html">GLM</a>
    </li>
    <li>
      <a href="knn.html">KNN</a>
    </li>
    <li>
      <a href="decision_trees.html">Decision Trees</a>
    </li>
    <li>
      <a href="random_forest.html">Random Forest</a>
    </li>
    <li>
      <a href="svm.html">SVM</a>
    </li>
  </ul>
</li>
<li>
  <a href="GAM.html">GAM</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">K Nearest Neighbors - KNN</h1>

</div>


<pre class="r"><code>library(class)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre class="r"><code>library (ROCR)
library(MASS)</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre class="r"><code>library(hmeasure)
source(&quot;funcs.R&quot;)
data(Pima.te) </code></pre>
<p>Cargamos los datos que utilizaremos para el entrenamiento, el test y la validación:</p>
<pre class="r"><code>dataTrain &lt;- readRDS(&quot;datasetTrain.rds&quot;)
dataTest &lt;- readRDS(&quot;datasetTest.rds&quot;)
dataValidation &lt;- readRDS(&quot;datasetValidation.rds&quot;)

#dataTrain&lt;-  readRDS(&quot;datasetTrainTransformed.rds&quot;)
#dataTest&lt;-  readRDS(&quot;datasetTestTransformed.rds&quot;)
#dataValidation&lt;-  readRDS(&quot;validationTransformed.rds&quot;)</code></pre>
<p>Procedemos a despejar de los dataset la variable objetivo original SalePrice. De la cual creamos la variable GrupoPrecio, del tipo categorica.</p>
<pre class="r"><code>dataTrain &lt;- dataTrain %&gt;% dplyr::select(-SalePrice)
dataTest &lt;- dataTest %&gt;% dplyr::select(-SalePrice)

dataValidation &lt;- dataValidation %&gt;% dplyr::select(-SalePrice)

group &lt;- c(&#39;TotalSF&#39;,&#39;LotArea&#39;,&#39;GrLivArea&#39;,&#39;GrupoPrecio&#39;)

dataTrain &lt;- dataTrain %&gt;% dplyr::select(group)
dataTest &lt;- dataTest %&gt;% dplyr::select(group)

dataValidation &lt;- dataValidation %&gt;% dplyr::select(group)</code></pre>
<p>A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test y finalmente con el grupo de validación.</p>
<pre class="r"><code>XTrain &lt;- dataTrain %&gt;% dplyr::select(-GrupoPrecio)
YTrain &lt;- dataTrain$GrupoPrecio

XTest &lt;- dataTest %&gt;% dplyr::select(-GrupoPrecio)
YTest &lt;- dataTest$GrupoPrecio

XValidation &lt;- dataValidation %&gt;% dplyr::select(-GrupoPrecio)
YValidation &lt;- dataValidation$GrupoPrecio</code></pre>
<pre class="r"><code>model &lt;- knn(XTrain, XTest, cl = YTrain, k=3)</code></pre>
<pre class="r"><code>tab_test &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))

(tab_test)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato    616   77
##   Caro       48   48</code></pre>
<pre class="r"><code>accuracy(tab_test)</code></pre>
<pre><code>## [1] 84.15716</code></pre>
<pre class="r"><code>knn_test_error &lt;- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_error)</code></pre>
<pre><code>## [1] 0.1584284</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_test, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>#scores.knn &lt;- attr(model, &quot;prob&quot;)
#scores.knn[model==&quot;No&quot;] &lt;- 1-scores.knn[model==&quot;No&quot;]
#scores &lt;- data.frame(LDA=scores.knn,kNN=scores.knn)

#results &lt;- HMeasure(YTest,scores)
#par(mfrow=c(2,2))
#plotROC(results,which=1)
#plotROC(results,which=2)
#plotROC(results,which=3)
#plotROC(results,which=4)</code></pre>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_test)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato    616   77
##   Caro       48   48
##                                           
##                Accuracy : 0.8416          
##                  95% CI : (0.8142, 0.8664)
##     No Information Rate : 0.8416          
##     P-Value [Acc &gt; NIR] : 0.52385         
##                                           
##                   Kappa : 0.3441          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.01227         
##                                           
##             Sensitivity : 0.9277          
##             Specificity : 0.3840          
##          Pos Pred Value : 0.8889          
##          Neg Pred Value : 0.5000          
##              Prevalence : 0.8416          
##          Detection Rate : 0.7807          
##    Detection Prevalence : 0.8783          
##       Balanced Accuracy : 0.6559          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>
<p>Obtemos el hiperparametro k (el numero de vecinos que determinaran la clase que predice el modelo), probando una series de valores y evaluando cual da una accuary mayor.</p>
<pre class="r"><code>i &lt;- 1
k &lt;- 1

for(i in 1:100){
  model &lt;- knn(XTrain, XTest, cl = YTrain, k=i)
  tab_test &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
  k[i] &lt;- accuracy(tab_test)
  opt &lt;- i
  cat(opt, &#39;=&#39;, k[i], &#39;&#39;)
}</code></pre>
<pre><code>## 1 = 82.25602 2 = 83.3967 3 = 84.15716 4 = 84.15716 5 = 84.41065 6 = 85.04436 7 = 84.66413 8 = 84.41065 9 = 85.04436 10 = 86.18504 11 = 86.31179 12 = 85.1711 13 = 85.1711 14 = 85.04436 15 = 85.42459 16 = 85.42459 17 = 85.04436 18 = 84.41065 19 = 84.91762 20 = 84.41065 21 = 84.53739 22 = 84.79087 23 = 84.66413 24 = 85.1711 25 = 84.91762 26 = 84.91762 27 = 85.29785 28 = 85.29785 29 = 84.91762 30 = 84.91762 31 = 84.91762 32 = 85.29785 33 = 85.1711 34 = 84.79087 35 = 84.66413 36 = 84.79087 37 = 84.66413 38 = 84.79087 39 = 84.53739 40 = 84.79087 41 = 85.04436 42 = 85.04436 43 = 85.42459 44 = 84.91762 45 = 85.04436 46 = 84.66413 47 = 84.79087 48 = 85.04436 49 = 84.79087 50 = 84.79087 51 = 84.41065 52 = 84.79087 53 = 84.66413 54 = 84.91762 55 = 84.53739 56 = 84.66413 57 = 84.79087 58 = 84.53739 59 = 84.53739 60 = 84.2839 61 = 83.90368 62 = 83.65019 63 = 83.90368 64 = 84.03042 65 = 83.90368 66 = 83.90368 67 = 83.77693 68 = 83.90368 69 = 83.90368 70 = 83.65019 71 = 83.77693 72 = 83.90368 73 = 83.90368 74 = 83.77693 75 = 84.15716 76 = 84.03042 77 = 84.03042 78 = 84.03042 79 = 83.77693 80 = 84.15716 81 = 83.77693 82 = 84.15716 83 = 84.03042 84 = 84.15716 85 = 83.90368 86 = 84.2839 87 = 84.15716 88 = 84.41065 89 = 84.03042 90 = 84.15716 91 = 84.15716 92 = 84.03042 93 = 84.03042 94 = 83.65019 95 = 83.65019 96 = 83.77693 97 = 83.77693 98 = 83.77693 99 = 83.90368 100 = 84.15716</code></pre>
<pre class="r"><code>plot(k, type=&quot;b&quot;, xlab=&quot;K-Value&quot;, ylab=&quot;Accuracy level&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>(k)</code></pre>
<pre><code>##   [1] 82.25602 83.39670 84.15716 84.15716 84.41065 85.04436 84.66413 84.41065
##   [9] 85.04436 86.18504 86.31179 85.17110 85.17110 85.04436 85.42459 85.42459
##  [17] 85.04436 84.41065 84.91762 84.41065 84.53739 84.79087 84.66413 85.17110
##  [25] 84.91762 84.91762 85.29785 85.29785 84.91762 84.91762 84.91762 85.29785
##  [33] 85.17110 84.79087 84.66413 84.79087 84.66413 84.79087 84.53739 84.79087
##  [41] 85.04436 85.04436 85.42459 84.91762 85.04436 84.66413 84.79087 85.04436
##  [49] 84.79087 84.79087 84.41065 84.79087 84.66413 84.91762 84.53739 84.66413
##  [57] 84.79087 84.53739 84.53739 84.28390 83.90368 83.65019 83.90368 84.03042
##  [65] 83.90368 83.90368 83.77693 83.90368 83.90368 83.65019 83.77693 83.90368
##  [73] 83.90368 83.77693 84.15716 84.03042 84.03042 84.03042 83.77693 84.15716
##  [81] 83.77693 84.15716 84.03042 84.15716 83.90368 84.28390 84.15716 84.41065
##  [89] 84.03042 84.15716 84.15716 84.03042 84.03042 83.65019 83.65019 83.77693
##  [97] 83.77693 83.77693 83.90368 84.15716</code></pre>
<p>Una vez obtenida la k más optima podemos ver que el modelo funciona mejor.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XTest, cl = YTrain, k=11)</code></pre>
<pre class="r"><code>tab_test &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))

(tab_test)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato    636   80
##   Caro       28   45</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_test, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>accuracy(tab_test)</code></pre>
<pre><code>## [1] 86.31179</code></pre>
<pre class="r"><code>knn_test_error &lt;- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_error)</code></pre>
<pre><code>## [1] 0.1368821</code></pre>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_test)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato    636   80
##   Caro       28   45
##                                           
##                Accuracy : 0.8631          
##                  95% CI : (0.8371, 0.8863)
##     No Information Rate : 0.8416          
##     P-Value [Acc &gt; NIR] : 0.05178         
##                                           
##                   Kappa : 0.3824          
##                                           
##  Mcnemar&#39;s Test P-Value : 9.226e-07       
##                                           
##             Sensitivity : 0.9578          
##             Specificity : 0.3600          
##          Pos Pred Value : 0.8883          
##          Neg Pred Value : 0.6164          
##              Prevalence : 0.8416          
##          Detection Rate : 0.8061          
##    Detection Prevalence : 0.9075          
##       Balanced Accuracy : 0.6589          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>
<p>Utilizamos el conjunto de validación para comprobar nuestro modelo.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XValidation, cl = YTrain, k=11)</code></pre>
<pre class="r"><code>tab_validation &lt;- table(model, YValidation, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))

(tab_validation)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato    225   36
##   Caro       15   15</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_validation, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>accuracy(tab_validation)</code></pre>
<pre><code>## [1] 82.47423</code></pre>
<pre class="r"><code>knn_validation_error &lt;- calc_error_rate(predicted.value=model, true.value=YValidation)
(knn_validation_error)</code></pre>
<pre><code>## [1] 0.1752577</code></pre>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_validation)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato    225   36
##   Caro       15   15
##                                           
##                Accuracy : 0.8247          
##                  95% CI : (0.7761, 0.8666)
##     No Information Rate : 0.8247          
##     P-Value [Acc &gt; NIR] : 0.537322        
##                                           
##                   Kappa : 0.2764          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.005101        
##                                           
##             Sensitivity : 0.9375          
##             Specificity : 0.2941          
##          Pos Pred Value : 0.8621          
##          Neg Pred Value : 0.5000          
##              Prevalence : 0.8247          
##          Detection Rate : 0.7732          
##    Detection Prevalence : 0.8969          
##       Balanced Accuracy : 0.6158          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
