<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>K Nearest Neighbors - KNN</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ML</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Cluster.html">Clustering</a>
</li>
<li>
  <a href="PCA.html">PCA</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Aprendizaje supervisado
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="glm.html">GLM</a>
    </li>
    <li>
      <a href="knn.html">KNN</a>
    </li>
    <li>
      <a href="decision_trees.html">Decision Trees</a>
    </li>
    <li>
      <a href="random_forest.html">Random Forest</a>
    </li>
    <li>
      <a href="svm.html">SVM</a>
    </li>
  </ul>
</li>
<li>
  <a href="GAM.html">GAM</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">K Nearest Neighbors - KNN</h1>

</div>


<p>A continuación aplicaremos un modelo knn o k nearest neighbors a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según tenga “k” vecinos más cerca de un grupo o de otro. Es decir, calcula la distancia del elemento nuevo a cada uno de los existentes, y ordena dichas distancias de menor a mayor para ir seleccionando el grupo al que pertenece. Este grupo será, por tanto, el de mayor frecuencia con menores distancias.</p>
<p>El knn es un algoritmo de aprendizaje supervisado, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas.</p>
<p>Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test.</p>
<pre class="r"><code>library(class)
library(dplyr)
library(caret)
library (ROCR)
library(MASS)
library(hmeasure)
library(data.table)
library(MLeval)
source(&quot;funcs.R&quot;)
data(Pima.te)</code></pre>
<pre class="r"><code>dataTrain_origin &lt;- readRDS(&quot;datasetTrainModeloClasificador.rds&quot;)
dataTest_origin &lt;- readRDS(&quot;datasetTestModeloClasificador.rds&quot;)</code></pre>
<p>Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.</p>
<p>Nuestro modelo clasificará casas entre estos dos grupos.</p>
<pre class="r"><code>dataTrain &lt;- dataTrain_origin %&gt;% dplyr::select(-SalePrice)
dataTest &lt;- dataTest_origin %&gt;% dplyr::select(-SalePrice)</code></pre>
<p>Para este modelo se han elegido un grupo de caracteristica del dataset original. Se han escogido debido a un analisis previo del conjunto de datos en el que mediante un modelo random forest se ha determinado el grupo de caracteristicas más importantes. A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test. Debido a que nuestros datos tiene variables categoricas, tenemos que transformarlas a numericas para el modelo knn.</p>
<pre class="r"><code>remove &lt;- c(&#39;GrupoPrecio&#39;)
col_to_factor &lt;- colnames(dataTrain) [! colnames(dataTrain) %in% remove]

dataTrain &lt;- dataTrain %&gt;% as_factor_all(col_to_factor)
dataTest &lt;- dataTest %&gt;% as_factor_all(col_to_factor)

XTrain &lt;- dataTrain %&gt;% dplyr::select(-GrupoPrecio)
YTrain &lt;- dataTrain$GrupoPrecio

XTest &lt;- dataTest %&gt;% dplyr::select(-GrupoPrecio)
YTest &lt;- dataTest$GrupoPrecio</code></pre>
<div id="entrenamiento-optimización-y-evaluación-del-modelo" class="section level3">
<h3>ENTRENAMIENTO, OPTIMIZACIÓN Y EVALUACIÓN DEL MODELO</h3>
<p>Entrenamos el modelo a la vez que buscamos el k más optimo para el conjunto de datos de train normalizados. A continuación evaluamos nuestro modelo con el conjunto de test normalizados con la información de train.</p>
<pre class="r"><code>#Normalización
ctrNorm &lt;- preProcess(x = XTrain, method = c(&quot;center&quot;, &quot;scale&quot;))

dataTrainNorm &lt;- predict(ctrNorm, dataTrain)

#Entrenamiento y busqueda de k más optimo
set.seed(400)
ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;, repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE)
knn &lt;- train(GrupoPrecio ~ ., data = dataTrainNorm, method = &quot;knn&quot;, trControl = ctrl, tuneLength = 30)</code></pre>
<pre><code>## Warning in train.default(x, y, weights = w, ...): The metric &quot;Accuracy&quot; was not
## in the result set. ROC will be used instead.</code></pre>
<pre class="r"><code>(knn)</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 1837 samples
##   26 predictor
##    2 classes: &#39;Barato&#39;, &#39;Caro&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 1653, 1654, 1653, 1653, 1654, 1653, ... 
## Resampling results across tuning parameters:
## 
##   k   ROC        Sens       Spec      
##    5  0.8400397  0.9781993  0.29523810
##    7  0.8767752  0.9811382  0.25952381
##    9  0.9039852  0.9817253  0.26904762
##   11  0.9122755  0.9842812  0.26190476
##   13  0.9170407  0.9858487  0.26190476
##   15  0.9193636  0.9866342  0.25952381
##   17  0.9204341  0.9880114  0.24047619
##   19  0.9194293  0.9880125  0.21904762
##   21  0.9228137  0.9893874  0.22380952
##   23  0.9245883  0.9903690  0.20714286
##   25  0.9257244  0.9915501  0.19761905
##   27  0.9249395  0.9917461  0.18333333
##   29  0.9277105  0.9913528  0.16190476
##   31  0.9309312  0.9919411  0.15476190
##   33  0.9308468  0.9927277  0.12142857
##   35  0.9317570  0.9927277  0.10476190
##   37  0.9317156  0.9935143  0.09761905
##   39  0.9319748  0.9937104  0.10714286
##   41  0.9335930  0.9937104  0.08571429
##   43  0.9351690  0.9943010  0.07619048
##   45  0.9363796  0.9944970  0.07142857
##   47  0.9365199  0.9948880  0.06428571
##   49  0.9358207  0.9952825  0.06428571
##   51  0.9350563  0.9948892  0.06428571
##   53  0.9347691  0.9958742  0.04523810
##   55  0.9353218  0.9956782  0.04047619
##   57  0.9357485  0.9962664  0.03809524
##   59  0.9355316  0.9968581  0.03333333
##   61  0.9361345  0.9966609  0.02857143
##   63  0.9359722  0.9972503  0.03095238
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was k = 47.</code></pre>
<pre class="r"><code>plot(knn)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>#Normalizamos con la información de train.
XTestNorm &lt;- predict(ctrNorm, XTest)
pred &lt;- predict(knn, newdata = XTestNorm )

cm &lt;- confusionMatrix(pred, YTest, mode = &quot;prec_recall&quot; )
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Barato Caro
##     Barato    719   57
##     Caro        7    6
##                                          
##                Accuracy : 0.9189         
##                  95% CI : (0.8976, 0.937)
##     No Information Rate : 0.9202         
##     P-Value [Acc &gt; NIR] : 0.585          
##                                          
##                   Kappa : 0.1342         
##                                          
##  Mcnemar&#39;s Test P-Value : 9.068e-10      
##                                          
##               Precision : 0.9265         
##                  Recall : 0.9904         
##                      F1 : 0.9574         
##              Prevalence : 0.9202         
##          Detection Rate : 0.9113         
##    Detection Prevalence : 0.9835         
##       Balanced Accuracy : 0.5428         
##                                          
##        &#39;Positive&#39; Class : Barato         
## </code></pre>
<pre class="r"><code>tab_test &lt;- table(pred, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
draw_confusion_matrix(tab_test, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<div id="aplicamos-pca" class="section level5">
<h5>APLICAMOS PCA</h5>
<pre class="r"><code>dataTrain_origin_PCA &lt;- readRDS(&quot;datasetTrainModeloClasificadorPCA.rds&quot;)
dataTest_origin_PCA &lt;- readRDS(&quot;datasetTestModeloClasificadorPCA.rds&quot;)

PCATrain &lt;- as.data.table(cbind(dataTrain_origin_PCA$ind$coord, GrupoPrecio = dataTrain_origin %&gt;% dplyr::select(c(&quot;GrupoPrecio&quot;))))
PCATest &lt;- as.data.table(cbind(dataTest_origin_PCA$ind$coord, GrupoPrecio = dataTest_origin %&gt;% dplyr::select(c(&quot;GrupoPrecio&quot;))))

XPCATrain &lt;- PCATrain %&gt;% dplyr::select(-GrupoPrecio)
YPCATrain &lt;- PCATrain$GrupoPrecio
XPCATest &lt;- PCATest %&gt;% dplyr::select(-GrupoPrecio)
YPCATest &lt;- PCATest$GrupoPrecio

set.seed(400)
ctrl_pca &lt;- trainControl(method=&quot;repeatedcv&quot;,repeats = 3,classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE)
knn_pca &lt;- train(GrupoPrecio ~ ., data = PCATrain, method = &quot;knn&quot;, trControl = ctrl_pca, tuneLength = 30)</code></pre>
<pre><code>## Warning in train.default(x, y, weights = w, ...): The metric &quot;Accuracy&quot; was not
## in the result set. ROC will be used instead.</code></pre>
<pre class="r"><code>(knn_pca)</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 1837 samples
##   50 predictor
##    2 classes: &#39;Barato&#39;, &#39;Caro&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 1653, 1654, 1653, 1653, 1654, 1653, ... 
## Resampling results across tuning parameters:
## 
##   k   ROC        Sens       Spec      
##    5  0.8412379  0.9738810  0.21904762
##    7  0.8706548  0.9778153  0.22619048
##    9  0.8803959  0.9801694  0.19047619
##   11  0.8929267  0.9825247  0.20238095
##   13  0.8961235  0.9834992  0.18809524
##   15  0.8942155  0.9844820  0.18571429
##   17  0.8973935  0.9846780  0.18333333
##   19  0.9016498  0.9854647  0.17142857
##   21  0.9030207  0.9864497  0.15238095
##   23  0.9051251  0.9884140  0.14761905
##   25  0.9076684  0.9888026  0.15476190
##   27  0.9071224  0.9884116  0.14523810
##   29  0.9066801  0.9880137  0.14285714
##   31  0.9075557  0.9868395  0.14523810
##   33  0.9068684  0.9866423  0.14285714
##   35  0.9051864  0.9862490  0.12857143
##   37  0.9045340  0.9884105  0.11428571
##   39  0.9026327  0.9895893  0.10000000
##   41  0.9029672  0.9897877  0.08809524
##   43  0.9037768  0.9917519  0.07380952
##   45  0.9046942  0.9945017  0.07380952
##   47  0.9046087  0.9950876  0.06428571
##   49  0.9043474  0.9946966  0.06428571
##   51  0.9034490  0.9950899  0.05714286
##   53  0.9028450  0.9952872  0.04761905
##   55  0.9022860  0.9952883  0.03333333
##   57  0.9019546  0.9947001  0.03571429
##   59  0.9021642  0.9954867  0.03333333
##   61  0.9011967  0.9954844  0.03809524
##   63  0.9020660  0.9952860  0.02619048
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was k = 25.</code></pre>
<pre class="r"><code>plot(knn_pca)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>pred_pca &lt;- predict(knn_pca, newdata = XPCATest)

cm_pca &lt;- confusionMatrix(pred_pca, YPCATest, mode = &quot;prec_recall&quot; )
(cm_pca)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Barato Caro
##     Barato    712   47
##     Caro       14   16
##                                           
##                Accuracy : 0.9227          
##                  95% CI : (0.9018, 0.9403)
##     No Information Rate : 0.9202          
##     P-Value [Acc &gt; NIR] : 0.4289          
##                                           
##                   Kappa : 0.3085          
##                                           
##  Mcnemar&#39;s Test P-Value : 4.182e-05       
##                                           
##               Precision : 0.9381          
##                  Recall : 0.9807          
##                      F1 : 0.9589          
##              Prevalence : 0.9202          
##          Detection Rate : 0.9024          
##    Detection Prevalence : 0.9620          
##       Balanced Accuracy : 0.6173          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>
<pre class="r"><code>tab_test_pca &lt;- table(pred_pca, YPCATest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
draw_confusion_matrix(tab_test_pca, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
</div>
</div>
<div id="evaluación" class="section level3">
<h3>EVALUACIÓN</h3>
<pre class="r"><code>res &lt;- evalm(list(knn_pca,knn),gnames = c(&#39;knn_pca&#39;,&#39;knn&#39;))</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-6-1.png" width="672" /><img src="knn_files/figure-html/unnamed-chunk-6-2.png" width="672" /><img src="knn_files/figure-html/unnamed-chunk-6-3.png" width="672" /><img src="knn_files/figure-html/unnamed-chunk-6-4.png" width="672" /></p>
<pre class="r"><code>saveRDS(knn_pca, &quot;knn.rds&quot;)</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
