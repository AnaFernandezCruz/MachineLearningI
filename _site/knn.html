<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>K Nearest Neighbors - KNN</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ML</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Cluster.html">Clustering</a>
</li>
<li>
  <a href="PCA.html">PCA</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Aprendizaje supervisado
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="glm.html">GLM</a>
    </li>
    <li>
      <a href="knn.html">KNN</a>
    </li>
    <li>
      <a href="decision_trees.html">Decision Trees</a>
    </li>
    <li>
      <a href="random_forest.html">Random Forest</a>
    </li>
    <li>
      <a href="svm.html">SVM</a>
    </li>
  </ul>
</li>
<li>
  <a href="GAM.html">GAM</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">K Nearest Neighbors - KNN</h1>

</div>


<p>A continuación aplicaremos un modelo knn o k nearest neighbors a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según tenga “k” vecinos más cerca de un grupo o de otro. Es decir, calcula la distancia del elemento nuevo a cada uno de los existentes, y ordena dichas distancias de menor a mayor para ir seleccionando el grupo al que pertenece. Este grupo será, por tanto, el de mayor frecuencia con menores distancias.</p>
<p>El knn es un algoritmo de aprendizaje supervisado, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas.</p>
<p>Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test:</p>
<pre class="r"><code>library(class)
library(dplyr)
library(caret)
library (ROCR)
library(MASS)
library(hmeasure)
source(&quot;funcs.R&quot;)
data(Pima.te) </code></pre>
<pre class="r"><code>dataTrain &lt;- readRDS(&quot;datasetTrain.rds&quot;)
dataTest &lt;- readRDS(&quot;datasetTest.rds&quot;)</code></pre>
<p>Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.</p>
<p>Nuestro modelo clasificará casas entre estos dos grupos.</p>
<pre class="r"><code>dataTrain &lt;- dataTrain %&gt;% dplyr::select(-SalePrice)
dataTest &lt;- dataTest %&gt;% dplyr::select(-SalePrice)</code></pre>
<p>Para este modelo se han elegido un grupo de caracteristica del dataset original. Son todas de numéricas y se han escogido debido a un analisis exploratorio de los datos previos y la realización de un modelo de randon forest que se explicara en otra sección del informe.</p>
<p>A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test.</p>
<pre class="r"><code>group &lt;- c(&#39;TotalSF&#39;,&#39;LotArea&#39;,&#39;GrLivArea&#39;,&#39;GrupoPrecio&#39;)

dataTrain &lt;- dataTrain %&gt;% dplyr::select(group)</code></pre>
<pre><code>## Note: Using an external vector in selections is ambiguous.
## i Use `all_of(group)` instead of `group` to silence this message.
## i See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.
## This message is displayed once per session.</code></pre>
<pre class="r"><code>dataTest &lt;- dataTest %&gt;% dplyr::select(group)</code></pre>
<pre class="r"><code>XTrain &lt;- dataTrain %&gt;% dplyr::select(-GrupoPrecio)
YTrain &lt;- dataTrain$GrupoPrecio

XTest &lt;- dataTest %&gt;% dplyr::select(-GrupoPrecio)
YTest &lt;- dataTest$GrupoPrecio</code></pre>
<p>Inciamos el modelo entrenado con el conjunto de entrenamiento y evaluando como se comporta con el mismo. Si los grupos estan bien separados con una k mayor que uno deberia de dar un porcentaje de acierto alto, porque se evalua contra el mismo conjutno que usamos para entrenar el modelo.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XTrain, cl = YTrain, k=3)</code></pre>
<pre class="r"><code>tab_train &lt;- table(model, YTrain, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
(tab_train)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato   1528   90
##   Caro       53  166</code></pre>
<pre class="r"><code>accuracy(tab_train)</code></pre>
<pre><code>## [1] 92.21557</code></pre>
<pre class="r"><code>knn_train_error &lt;- calc_error_rate(predicted.value=model, true.value=YTrain)
(knn_train_error)</code></pre>
<pre><code>## [1] 0.07784431</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_train, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_train)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato   1528   90
##   Caro       53  166
##                                          
##                Accuracy : 0.9222         
##                  95% CI : (0.9089, 0.934)
##     No Information Rate : 0.8606         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.6546         
##                                          
##  Mcnemar&#39;s Test P-Value : 0.002608       
##                                          
##             Sensitivity : 0.9665         
##             Specificity : 0.6484         
##          Pos Pred Value : 0.9444         
##          Neg Pred Value : 0.7580         
##              Prevalence : 0.8606         
##          Detection Rate : 0.8318         
##    Detection Prevalence : 0.8808         
##       Balanced Accuracy : 0.8075         
##                                          
##        &#39;Positive&#39; Class : Barato         
## </code></pre>
<p>Podemos observar que al acierto es alto pero no como deberia ya que intenta clasificar los mismos elementos que se usaron para entrenar. Esto muestra que posiblemente se tengan que volver a escoger un grupo de caracteristicas diferentes.</p>
<p>Procedemos a evaluar el modelo con nuestro conjunto de test y buscar el valor de k más optimo.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XTest, cl = YTrain, k=3)</code></pre>
<pre class="r"><code>tab_test &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
(tab_test)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato    616   77
##   Caro       48   48</code></pre>
<pre class="r"><code>accuracy(tab_test)</code></pre>
<pre><code>## [1] 84.15716</code></pre>
<pre class="r"><code>knn_test_error &lt;- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_error)</code></pre>
<pre><code>## [1] 0.1584284</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_test, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_test)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato    616   77
##   Caro       48   48
##                                           
##                Accuracy : 0.8416          
##                  95% CI : (0.8142, 0.8664)
##     No Information Rate : 0.8416          
##     P-Value [Acc &gt; NIR] : 0.52385         
##                                           
##                   Kappa : 0.3441          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.01227         
##                                           
##             Sensitivity : 0.9277          
##             Specificity : 0.3840          
##          Pos Pred Value : 0.8889          
##          Neg Pred Value : 0.5000          
##              Prevalence : 0.8416          
##          Detection Rate : 0.7807          
##    Detection Prevalence : 0.8783          
##       Balanced Accuracy : 0.6559          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>
<p>Obtemos el hiperparametro k (el numero de vecinos que determinaran la clase que predice el modelo), probando una series de valores y evaluando cual da un % de acierto mayor.</p>
<pre class="r"><code>i &lt;- 1
k &lt;- 1

for(i in 1:100){
  model &lt;- knn(XTrain, XTest, cl = YTrain, k=i)
  tab_test &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
  k[i] &lt;- accuracy(tab_test)
  opt &lt;- i
  cat(opt, &#39;=&#39;, k[i], &#39;&#39;)
}</code></pre>
<pre><code>## 1 = 82.25602 2 = 83.3967 3 = 84.15716 4 = 85.80482 5 = 84.41065 6 = 84.53739 7 = 84.66413 8 = 84.53739 9 = 85.04436 10 = 84.91762 11 = 86.31179 12 = 84.66413 13 = 85.1711 14 = 85.29785 15 = 85.42459 16 = 84.91762 17 = 85.04436 18 = 85.42459 19 = 84.91762 20 = 85.04436 21 = 84.53739 22 = 84.79087 23 = 84.66413 24 = 84.79087 25 = 84.91762 26 = 84.53739 27 = 85.29785 28 = 84.79087 29 = 84.91762 30 = 84.91762 31 = 84.91762 32 = 84.41065 33 = 85.1711 34 = 85.1711 35 = 84.66413 36 = 84.66413 37 = 84.66413 38 = 84.79087 39 = 84.53739 40 = 84.66413 41 = 85.04436 42 = 85.1711 43 = 85.42459 44 = 84.91762 45 = 85.04436 46 = 84.79087 47 = 84.79087 48 = 84.79087 49 = 84.79087 50 = 84.79087 51 = 84.41065 52 = 84.53739 53 = 84.66413 54 = 84.66413 55 = 84.53739 56 = 84.41065 57 = 84.79087 58 = 84.53739 59 = 84.53739 60 = 84.15716 61 = 83.90368 62 = 84.03042 63 = 83.90368 64 = 84.15716 65 = 83.90368 66 = 83.77693 67 = 83.77693 68 = 83.65019 69 = 83.90368 70 = 84.2839 71 = 83.77693 72 = 83.26996 73 = 83.90368 74 = 83.90368 75 = 84.15716 76 = 84.03042 77 = 84.03042 78 = 83.77693 79 = 83.77693 80 = 83.90368 81 = 83.77693 82 = 83.90368 83 = 84.03042 84 = 84.15716 85 = 83.90368 86 = 83.90368 87 = 84.15716 88 = 84.03042 89 = 84.03042 90 = 84.03042 91 = 84.15716 92 = 83.90368 93 = 84.03042 94 = 83.90368 95 = 83.65019 96 = 83.3967 97 = 83.77693 98 = 83.65019 99 = 83.90368 100 = 83.77693</code></pre>
<pre class="r"><code>plot(k, type=&quot;b&quot;, xlab=&quot;K-Value&quot;, ylab=&quot;Accuracy level&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-9-1.png" width="672" /> Una vez obtenida la k más optima, evaluamos al modelo con el conjunto de test y con el valor de k que hemos obtenido. El modelo deberia de funcionar algo mejor.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XTest, cl = YTrain, k=11)

saveRDS(model, &quot;modelKNN.rds&quot;)</code></pre>
<pre class="r"><code>tab_test_h &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))

(tab_test_h)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato    636   80
##   Caro       28   45</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_test_h, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>accuracy(tab_test_h)</code></pre>
<pre><code>## [1] 86.31179</code></pre>
<pre class="r"><code>knn_test_h_error &lt;- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_h_error)</code></pre>
<pre><code>## [1] 0.1368821</code></pre>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_test_h)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato    636   80
##   Caro       28   45
##                                           
##                Accuracy : 0.8631          
##                  95% CI : (0.8371, 0.8863)
##     No Information Rate : 0.8416          
##     P-Value [Acc &gt; NIR] : 0.05178         
##                                           
##                   Kappa : 0.3824          
##                                           
##  Mcnemar&#39;s Test P-Value : 9.226e-07       
##                                           
##             Sensitivity : 0.9578          
##             Specificity : 0.3600          
##          Pos Pred Value : 0.8883          
##          Neg Pred Value : 0.6164          
##              Prevalence : 0.8416          
##          Detection Rate : 0.8061          
##    Detection Prevalence : 0.9075          
##       Balanced Accuracy : 0.6589          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
