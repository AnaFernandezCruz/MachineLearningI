<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>K Nearest Neighbors - KNN</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ML</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Cluster.html">Clustering</a>
</li>
<li>
  <a href="PCA.html">PCA</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Aprendizaje supervisado
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="glm.html">GLM</a>
    </li>
    <li>
      <a href="knn.html">KNN</a>
    </li>
    <li>
      <a href="decision_trees.html">Decision Trees</a>
    </li>
    <li>
      <a href="random_forest.html">Random Forest</a>
    </li>
    <li>
      <a href="svm.html">SVM</a>
    </li>
  </ul>
</li>
<li>
  <a href="GAM.html">GAM</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">K Nearest Neighbors - KNN</h1>

</div>


<p>A continuación aplicaremos un modelo knn o k nearest neighbors a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según tenga “k” vecinos más cerca de un grupo o de otro. Es decir, calcula la distancia del elemento nuevo a cada uno de los existentes, y ordena dichas distancias de menor a mayor para ir seleccionando el grupo al que pertenece. Este grupo será, por tanto, el de mayor frecuencia con menores distancias.</p>
<p>El knn es un algoritmo de aprendizaje supervisado, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas.</p>
<p>Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test:</p>
<pre class="r"><code>library(class)
library(dplyr)
library(caret)
library (ROCR)
library(MASS)
library(hmeasure)
source(&quot;funcs.R&quot;)
data(Pima.te) </code></pre>
<pre class="r"><code>dataTrain &lt;- readRDS(&quot;datasetTrain.rds&quot;)
dataTest &lt;- readRDS(&quot;datasetTest.rds&quot;)</code></pre>
<p>Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.</p>
<p>Nuestro modelo clasificará casas entre estos dos grupos.</p>
<pre class="r"><code>dataTrain &lt;- dataTrain %&gt;% dplyr::select(-SalePrice)
dataTest &lt;- dataTest %&gt;% dplyr::select(-SalePrice)</code></pre>
<p>Para este modelo se han elegido un grupo de caracteristica del dataset original. Son todas de numéricas y se han escogido debido a un analisis exploratorio de los datos previos y la realización de un modelo de randon forest que se explicara en otra sección del informe.</p>
<p>A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test.</p>
<pre class="r"><code>group &lt;- c(&#39;TotalSF&#39;,&#39;LotArea&#39;,&#39;GrLivArea&#39;,&#39;GrupoPrecio&#39;)

dataTrain &lt;- dataTrain %&gt;% dplyr::select(group)
dataTest &lt;- dataTest %&gt;% dplyr::select(group)</code></pre>
<pre class="r"><code>XTrain &lt;- dataTrain %&gt;% dplyr::select(-GrupoPrecio)
YTrain &lt;- dataTrain$GrupoPrecio

XTest &lt;- dataTest %&gt;% dplyr::select(-GrupoPrecio)
YTest &lt;- dataTest$GrupoPrecio</code></pre>
<p>Inciamos el modelo entrenado con el conjunto de entrenamiento y evaluando como se comporta con el mismo. Si los grupos estan bien separados con una k mayor que uno deberia de dar un porcentaje de acierto alto, porque se evalua contra el mismo conjutno que usamos para entrenar el modelo.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XTrain, cl = YTrain, k=3)</code></pre>
<pre class="r"><code>tab_train &lt;- table(model, YTrain, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
(tab_train)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato   1528   90
##   Caro       53  166</code></pre>
<pre class="r"><code>accuracy(tab_train)</code></pre>
<pre><code>## [1] 92.21557</code></pre>
<pre class="r"><code>knn_train_error &lt;- calc_error_rate(predicted.value=model, true.value=YTrain)
(knn_train_error)</code></pre>
<pre><code>## [1] 0.07784431</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_train, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_train)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato   1528   90
##   Caro       53  166
##                                          
##                Accuracy : 0.9222         
##                  95% CI : (0.9089, 0.934)
##     No Information Rate : 0.8606         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.6546         
##                                          
##  Mcnemar&#39;s Test P-Value : 0.002608       
##                                          
##             Sensitivity : 0.9665         
##             Specificity : 0.6484         
##          Pos Pred Value : 0.9444         
##          Neg Pred Value : 0.7580         
##              Prevalence : 0.8606         
##          Detection Rate : 0.8318         
##    Detection Prevalence : 0.8808         
##       Balanced Accuracy : 0.8075         
##                                          
##        &#39;Positive&#39; Class : Barato         
## </code></pre>
<p>Podemos observar que al acierto es alto pero no como deberia ya que intenta clasificar los mismos elementos que se usaron para entrenar. Esto muestra que posiblemente se tengan que volver a escoger un grupo de caracteristicas diferentes.</p>
<p>Procedemos a evaluar el modelo con nuestro conjunto de test y buscar el valor de k más optimo.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XTest, cl = YTrain, k=3)</code></pre>
<pre class="r"><code>tab_test &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
(tab_test)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato    616   77
##   Caro       48   48</code></pre>
<pre class="r"><code>accuracy(tab_test)</code></pre>
<pre><code>## [1] 84.15716</code></pre>
<pre class="r"><code>knn_test_error &lt;- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_error)</code></pre>
<pre><code>## [1] 0.1584284</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_test, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_test)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato    616   77
##   Caro       48   48
##                                           
##                Accuracy : 0.8416          
##                  95% CI : (0.8142, 0.8664)
##     No Information Rate : 0.8416          
##     P-Value [Acc &gt; NIR] : 0.52385         
##                                           
##                   Kappa : 0.3441          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.01227         
##                                           
##             Sensitivity : 0.9277          
##             Specificity : 0.3840          
##          Pos Pred Value : 0.8889          
##          Neg Pred Value : 0.5000          
##              Prevalence : 0.8416          
##          Detection Rate : 0.7807          
##    Detection Prevalence : 0.8783          
##       Balanced Accuracy : 0.6559          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>
<p>Obtemos el hiperparametro k (el numero de vecinos que determinaran la clase que predice el modelo), probando una series de valores y evaluando cual da un % de acierto mayor.</p>
<pre class="r"><code>i &lt;- 1
k &lt;- 1

for(i in 1:100){
  model &lt;- knn(XTrain, XTest, cl = YTrain, k=i)
  tab_test &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
  k[i] &lt;- accuracy(tab_test)
  opt &lt;- i
  cat(opt, &#39;=&#39;, k[i], &#39;&#39;)
}</code></pre>
<pre><code>## 1 = 82.25602 2 = 82.76299 3 = 84.15716 4 = 83.65019 5 = 84.41065 6 = 85.04436 7 = 84.66413 8 = 85.04436 9 = 85.04436 10 = 85.04436 11 = 86.31179 12 = 85.1711 13 = 85.1711 14 = 85.04436 15 = 85.42459 16 = 84.66413 17 = 85.04436 18 = 84.79087 19 = 84.91762 20 = 85.1711 21 = 84.53739 22 = 84.91762 23 = 84.66413 24 = 84.2839 25 = 84.91762 26 = 85.29785 27 = 85.29785 28 = 85.29785 29 = 84.91762 30 = 84.15716 31 = 84.91762 32 = 85.04436 33 = 85.1711 34 = 84.53739 35 = 84.66413 36 = 84.53739 37 = 84.66413 38 = 84.66413 39 = 84.53739 40 = 84.66413 41 = 85.04436 42 = 85.29785 43 = 85.42459 44 = 85.29785 45 = 85.04436 46 = 84.79087 47 = 84.79087 48 = 85.04436 49 = 84.79087 50 = 84.79087 51 = 84.41065 52 = 84.91762 53 = 84.53739 54 = 84.53739 55 = 84.53739 56 = 84.66413 57 = 84.79087 58 = 84.53739 59 = 84.53739 60 = 84.2839 61 = 83.90368 62 = 84.03042 63 = 83.90368 64 = 83.90368 65 = 83.90368 66 = 83.77693 67 = 83.77693 68 = 83.90368 69 = 83.90368 70 = 83.90368 71 = 83.77693 72 = 83.90368 73 = 83.90368 74 = 83.90368 75 = 84.03042 76 = 83.90368 77 = 84.03042 78 = 83.90368 79 = 83.77693 80 = 84.03042 81 = 83.77693 82 = 84.03042 83 = 84.03042 84 = 84.03042 85 = 83.90368 86 = 84.15716 87 = 84.15716 88 = 84.03042 89 = 84.03042 90 = 83.90368 91 = 84.15716 92 = 84.03042 93 = 84.03042 94 = 83.90368 95 = 83.65019 96 = 83.77693 97 = 83.77693 98 = 83.77693 99 = 83.90368 100 = 84.03042</code></pre>
<pre class="r"><code>plot(k, type=&quot;b&quot;, xlab=&quot;K-Value&quot;, ylab=&quot;Accuracy level&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-9-1.png" width="672" /> Una vez obtenida la k más optima, evaluamos al modelo con el conjunto de test y con el valor de k que hemos obtenido. El modelo deberia de funcionar algo mejor.</p>
<pre class="r"><code>model &lt;- knn(XTrain, XTest, cl = YTrain, k=11)

saveRDS(model, &quot;modelKNN.rds&quot;)</code></pre>
<pre class="r"><code>tab_test_h &lt;- table(model, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))

(tab_test_h)</code></pre>
<pre><code>##         Predichos
## Actual   Barato Caro
##   Barato    636   80
##   Caro       28   45</code></pre>
<pre class="r"><code>draw_confusion_matrix(tab_test_h, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>accuracy(tab_test_h)</code></pre>
<pre><code>## [1] 86.31179</code></pre>
<pre class="r"><code>knn_test_h_error &lt;- calc_error_rate(predicted.value=model, true.value=YTest)
(knn_test_h_error)</code></pre>
<pre><code>## [1] 0.1368821</code></pre>
<pre class="r"><code>cm &lt;- confusionMatrix(tab_test_h)
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##         Predichos
## Actual   Barato Caro
##   Barato    636   80
##   Caro       28   45
##                                           
##                Accuracy : 0.8631          
##                  95% CI : (0.8371, 0.8863)
##     No Information Rate : 0.8416          
##     P-Value [Acc &gt; NIR] : 0.05178         
##                                           
##                   Kappa : 0.3824          
##                                           
##  Mcnemar&#39;s Test P-Value : 9.226e-07       
##                                           
##             Sensitivity : 0.9578          
##             Specificity : 0.3600          
##          Pos Pred Value : 0.8883          
##          Neg Pred Value : 0.6164          
##              Prevalence : 0.8416          
##          Detection Rate : 0.8061          
##    Detection Prevalence : 0.9075          
##       Balanced Accuracy : 0.6589          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
