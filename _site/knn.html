<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>K Nearest Neighbors - KNN</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ML</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Cluster.html">Clustering</a>
</li>
<li>
  <a href="PCA.html">PCA</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Clasificadores
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="GAMLogit.html">GAM</a>
    </li>
    <li>
      <a href="glm.html">GLM</a>
    </li>
    <li>
      <a href="knn.html">KNN</a>
    </li>
    <li>
      <a href="decision_trees.html">Decision Trees</a>
    </li>
    <li>
      <a href="random_forest.html">Random Forest</a>
    </li>
    <li>
      <a href="svm.html">SVM</a>
    </li>
  </ul>
</li>
<li>
  <a href="GAM.html">GAM - regresión</a>
</li>
<li>
  <a href="evaluacion.html">Evaluación</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">K Nearest Neighbors - KNN</h1>

</div>


<p>A continuación aplicaremos un modelo knn o k nearest neighbors a nuestro grupo de datos. El algoritmo clasifica cada dato nuevo en el grupo que corresponda, según tenga “k” vecinos más cerca de un grupo o de otro. Es decir, calcula la distancia del elemento nuevo a cada uno de los existentes, y ordena dichas distancias de menor a mayor para ir seleccionando el grupo al que pertenece. Este grupo será, por tanto, el de mayor frecuencia con menores distancias.</p>
<p>El knn es un algoritmo de aprendizaje supervisado, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas.</p>
<p>Cargamos las librerias y los datos que utilizaremos para el entrenamiento, con el conjunto de train, y la evaluación del modelo con el conjunto de test.</p>
<pre class="r"><code>library(class)
library(dplyr)
library(caret)
library (ROCR)
library(MASS)
library(hmeasure)
library(data.table)
library(MLeval)
library(DMwR)
source(&quot;funcs.R&quot;)
data(Pima.te)</code></pre>
<pre class="r"><code>dataTrain_origin &lt;- readRDS(&quot;datasetTrainModeloClasificador.rds&quot;)
dataTest_origin &lt;- readRDS(&quot;datasetTestModeloClasificador.rds&quot;)</code></pre>
<p>Procedemos a despejar de los dataset (train y test) la variable objetivo original SalePrice. De la cual ya hemos creamos la variable GrupoPrecio, del tipo categorica. Separando asi por una parte un grupo de casas baratas y otro grupo de casas caras.</p>
<p>Nuestro modelo clasificará casas entre estos dos grupos.</p>
<pre class="r"><code>dataTrain &lt;- dataTrain_origin %&gt;% dplyr::select(-SalePrice)
dataTest &lt;- dataTest_origin %&gt;% dplyr::select(-SalePrice)</code></pre>
<p>Para este modelo se han elegido un grupo de caracteristica del dataset original. Se han escogido debido a un analisis previo del conjunto de datos en el que mediante un modelo random forest se ha determinado el grupo de caracteristicas más importantes. A continuación preparamos los dataset para entrenar el modelo y posteriormente evaluar como se comporta con el conjunto de test. Debido a que nuestros datos tiene variables categoricas, tenemos que transformarlas a numericas para el modelo knn.</p>
<pre class="r"><code>remove &lt;- c(&#39;GrupoPrecio&#39;)
col_to_factor &lt;- colnames(dataTrain) [! colnames(dataTrain) %in% remove]

dataTrain &lt;- dataTrain %&gt;% as_factor_all(col_to_factor)
dataTest &lt;- dataTest %&gt;% as_factor_all(col_to_factor)

XTrain &lt;- dataTrain %&gt;% dplyr::select(-GrupoPrecio)
YTrain &lt;- dataTrain$GrupoPrecio

XTest &lt;- dataTest %&gt;% dplyr::select(-GrupoPrecio)
YTest &lt;- dataTest$GrupoPrecio</code></pre>
<div id="entrenamiento-optimización-y-evaluación-del-modelo" class="section level3">
<h3>ENTRENAMIENTO, OPTIMIZACIÓN Y EVALUACIÓN DEL MODELO</h3>
<p>Entrenamos el modelo a la vez que buscamos el k más optimo para el conjunto de datos de train normalizados. A continuación evaluamos nuestro modelo con el conjunto de test normalizados con la información de train. Al tener un dataset desbalanceado se ha utilizado el parametros “smote” para equilibrar la clase minoritaria.</p>
<pre class="r"><code>#Normalización
ctrNorm &lt;- preProcess(x = XTrain, method = c(&quot;center&quot;, &quot;scale&quot;))

dataTrainNorm &lt;- predict(ctrNorm, dataTrain)

#Entrenamiento y busqueda de k más optimo
set.seed(400)
ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;, repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE, sampling = &quot;smote&quot;)
knn &lt;- train(GrupoPrecio ~ ., data = dataTrainNorm, method = &quot;knn&quot;, trControl = ctrl, tuneLength = 30)</code></pre>
<pre><code>## Warning in train.default(x, y, weights = w, ...): The metric &quot;Accuracy&quot; was not
## in the result set. ROC will be used instead.</code></pre>
<pre class="r"><code>(knn)</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 1837 samples
##   25 predictor
##    2 classes: &#39;Barato&#39;, &#39;Caro&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 1653, 1654, 1653, 1653, 1654, 1653, ... 
## Addtional sampling using SMOTE
## 
## Resampling results across tuning parameters:
## 
##   k   ROC        Sens       Spec     
##    5  0.8936146  0.8554252  0.8000000
##    7  0.9115997  0.8521035  0.8380952
##    9  0.9161142  0.8485486  0.8666667
##   11  0.9237519  0.8467850  0.8952381
##   13  0.9216420  0.8487562  0.8761905
##   15  0.9249291  0.8483502  0.9000000
##   17  0.9255189  0.8479626  0.8880952
##   19  0.9272363  0.8426639  0.9023810
##   21  0.9308650  0.8473756  0.8976190
##   23  0.9314613  0.8477619  0.9023810
##   25  0.9301348  0.8450226  0.8857143
##   27  0.9297287  0.8485602  0.8857143
##   29  0.9281153  0.8473872  0.8857143
##   31  0.9308153  0.8460053  0.8904762
##   33  0.9285128  0.8440388  0.8809524
##   35  0.9250750  0.8460135  0.8690476
##   37  0.9270559  0.8456120  0.8738095
##   39  0.9272573  0.8446293  0.8880952
##   41  0.9283448  0.8436443  0.8833333
##   43  0.9266317  0.8477724  0.8833333
##   45  0.9281090  0.8477805  0.8952381
##   47  0.9265410  0.8399211  0.8880952
##   49  0.9259172  0.8430537  0.8880952
##   51  0.9298674  0.8416963  0.8809524
##   53  0.9268113  0.8387435  0.8857143
##   55  0.9292863  0.8420745  0.8857143
##   57  0.9271916  0.8391356  0.8809524
##   59  0.9269699  0.8379371  0.8880952
##   61  0.9263803  0.8420803  0.8928571
##   63  0.9285934  0.8350157  0.8928571
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was k = 23.</code></pre>
<pre class="r"><code>plot(knn)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>#Normalizamos con la información de train.
XTestNorm &lt;- predict(ctrNorm, XTest)
pred &lt;- predict(knn, newdata = XTestNorm )

cm &lt;- confusionMatrix(pred, YTest, mode = &quot;prec_recall&quot; )
(cm)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Barato Caro
##     Barato    606    7
##     Caro      120   56
##                                          
##                Accuracy : 0.839          
##                  95% CI : (0.8115, 0.864)
##     No Information Rate : 0.9202         
##     P-Value [Acc &gt; NIR] : 1              
##                                          
##                   Kappa : 0.3978         
##                                          
##  Mcnemar&#39;s Test P-Value : &lt;2e-16         
##                                          
##               Precision : 0.9886         
##                  Recall : 0.8347         
##                      F1 : 0.9052         
##              Prevalence : 0.9202         
##          Detection Rate : 0.7681         
##    Detection Prevalence : 0.7769         
##       Balanced Accuracy : 0.8618         
##                                          
##        &#39;Positive&#39; Class : Barato         
## </code></pre>
<pre class="r"><code>tab_test &lt;- table(pred, YTest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
draw_confusion_matrix(tab_test, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<div id="aplicamos-pca" class="section level5">
<h5>APLICAMOS PCA</h5>
<pre class="r"><code>dataTrain_origin_PCA &lt;- readRDS(&quot;datasetTrainModeloClasificadorPCA.rds&quot;)
dataTest_origin_PCA &lt;- readRDS(&quot;datasetTestModeloClasificadorPCA.rds&quot;)

PCATrain &lt;- as.data.table(cbind(dataTrain_origin_PCA$ind$coord, GrupoPrecio = dataTrain_origin %&gt;% dplyr::select(c(&quot;GrupoPrecio&quot;))))
PCATest &lt;- as.data.table(cbind(dataTest_origin_PCA$ind$coord, GrupoPrecio = dataTest_origin %&gt;% dplyr::select(c(&quot;GrupoPrecio&quot;))))

XPCATrain &lt;- PCATrain %&gt;% dplyr::select(-GrupoPrecio)
YPCATrain &lt;- PCATrain$GrupoPrecio
XPCATest &lt;- PCATest %&gt;% dplyr::select(-GrupoPrecio)
YPCATest &lt;- PCATest$GrupoPrecio

set.seed(400)
ctrl_pca &lt;- trainControl(method=&quot;repeatedcv&quot;,repeats = 3,classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE, sampling = &quot;smote&quot;)
knn_pca &lt;- train(GrupoPrecio ~ ., data = PCATrain, method = &quot;knn&quot;, trControl = ctrl_pca, tuneLength = 30)</code></pre>
<pre><code>## Warning in train.default(x, y, weights = w, ...): The metric &quot;Accuracy&quot; was not
## in the result set. ROC will be used instead.</code></pre>
<pre class="r"><code>(knn_pca)</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 1837 samples
##   50 predictor
##    2 classes: &#39;Barato&#39;, &#39;Caro&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 1653, 1654, 1653, 1653, 1654, 1653, ... 
## Addtional sampling using SMOTE
## 
## Resampling results across tuning parameters:
## 
##   k   ROC        Sens       Spec     
##    5  0.8938721  0.8444332  0.8142857
##    7  0.9056860  0.8450249  0.8452381
##    9  0.9098713  0.8353846  0.8523810
##   11  0.9079793  0.8326465  0.8452381
##   13  0.9064945  0.8304734  0.8428571
##   15  0.9066471  0.8324365  0.8309524
##   17  0.9057588  0.8338137  0.8404762
##   19  0.9068216  0.8300928  0.8452381
##   21  0.9063745  0.8277294  0.8357143
##   23  0.9057847  0.8336269  0.8261905
##   25  0.9076173  0.8310732  0.8238095
##   27  0.9079391  0.8387377  0.8238095
##   29  0.9062419  0.8395150  0.8095238
##   31  0.9071260  0.8399025  0.8214286
##   33  0.9077156  0.8397169  0.8119048
##   35  0.9087294  0.8377515  0.8238095
##   37  0.9081627  0.8428634  0.8023810
##   39  0.9081157  0.8395197  0.7976190
##   41  0.9079702  0.8402970  0.8119048
##   43  0.9109866  0.8414921  0.8166667
##   45  0.9113493  0.8430734  0.8095238
##   47  0.9080827  0.8440457  0.8047619
##   49  0.9111256  0.8462049  0.8238095
##   51  0.9115650  0.8479673  0.8000000
##   53  0.9098791  0.8487644  0.8119048
##   55  0.9118369  0.8467838  0.8238095
##   57  0.9140251  0.8489581  0.8119048
##   59  0.9153156  0.8493561  0.8166667
##   61  0.9142587  0.8489732  0.8309524
##   63  0.9131831  0.8472027  0.8309524
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was k = 59.</code></pre>
<pre class="r"><code>plot(knn_pca)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>pred_pca &lt;- predict(knn_pca, newdata = XPCATest)

cm_pca &lt;- confusionMatrix(pred_pca, YPCATest, mode = &quot;prec_recall&quot; )
(cm_pca)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Barato Caro
##     Barato    625   19
##     Caro      101   44
##                                           
##                Accuracy : 0.8479          
##                  95% CI : (0.8209, 0.8723)
##     No Information Rate : 0.9202          
##     P-Value [Acc &gt; NIR] : 1               
##                                           
##                   Kappa : 0.3508          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.422e-13       
##                                           
##               Precision : 0.9705          
##                  Recall : 0.8609          
##                      F1 : 0.9124          
##              Prevalence : 0.9202          
##          Detection Rate : 0.7921          
##    Detection Prevalence : 0.8162          
##       Balanced Accuracy : 0.7796          
##                                           
##        &#39;Positive&#39; Class : Barato          
## </code></pre>
<pre class="r"><code>tab_test_pca &lt;- table(pred_pca, YPCATest, dnn = c(&quot;Actual&quot;, &quot;Predichos&quot;))
draw_confusion_matrix(tab_test_pca, &quot;Actual&quot;, &quot;Predichos&quot;)</code></pre>
<p><img src="knn_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
</div>
</div>
<div id="evaluación" class="section level3">
<h3>EVALUACIÓN</h3>
<p><img src="knn_files/figure-html/unnamed-chunk-6-1.png" width="1728" /></p>
<p><img src="knn_files/figure-html/unnamed-chunk-7-1.png" width="1728" /></p>
<p><img src="knn_files/figure-html/unnamed-chunk-8-1.png" width="1728" /></p>
<p><img src="knn_files/figure-html/unnamed-chunk-9-1.png" width="1728" /></p>
<pre class="r"><code>saveRDS(knn_pca, &quot;knn_pca.rds&quot;)
saveRDS(knn, &quot;knn.rds&quot;)</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
