---
title: "Evaluación final"
output: html_document
---

Procedemos a cargar, evaluar y comparar todos los clasificadores diseñados para nuestro dataset. Una vez evaluados eligiremos cual se comporta mejor y clasificaremos el conjunto de evaluación comprobando definitivamente como de bueno es nuestro clasificador. 

```{r}
library(MLeval)
source("funcs.R")

knn <- readRDS("knn.rds")
knn_pca <- readRDS("knn_pca.rds")
svm <- readRDS("svm.rds")
svm_pca <- readRDS("svm_pca.rds")
glm <- readRDS("glm.rds")
rf <- readRDS("randomforest_nopca.rds")
dt <- readRDS("house_tree_nopca.rds")
gam <- readRDS("modeloGAMLogisticRegressionCarosCaret.rds")

```


```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18}
res <- evalm(list(svm, svm_pca, knn, knn_pca, glm, rf, dt,gam), gnames = c('svm','svm_pca','knn', 'knn_pca', 'glm','rf', 'dt','gam'),rlinethick=0.8,fsize=30, showplots = TRUE , bins=20, plots = c("prg"))

```

```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18}
res <- evalm(list(svm, svm_pca, knn, knn_pca, glm, rf, dt,gam), gnames = c('svm','svm_pca','knn', 'knn_pca', 'glm','rf', 'dt','gam'),rlinethick=0.8,fsize=30, optimise="MCC", showplots = TRUE , bins=20, plots = c("pr"))

```

```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18}
res <- evalm(list(svm, svm_pca, knn, knn_pca, glm, rf, dt,gam), gnames = c('svm','svm_pca','knn', 'knn_pca', 'glm','rf', 'dt','gam'),rlinethick=0.8,fsize=30, optimise="MCC", showplots = TRUE , bins=20, plots = c("r"))

```

```{r ,echo=FALSE,message=FALSE, warning=FALSE, fig.height=18, fig.width=18}
res <- evalm(list(svm, svm_pca, knn, knn_pca, glm, rf, dt,gam), gnames = c('svm','svm_pca','knn', 'knn_pca', 'glm','rf', 'dt','gam'),rlinethick=0.8,fsize=30, optimise="MCC", showplots = TRUE , bins=20, plots = c("cc"))

```

Después de haber realizado el análisis de evaluación de cada modelo, llegamos a la conclusión que el mejor de los modelos es ___. A continuación usaremos el conjunto de datos de validación y evaluaremos como de bueno es el modelo.

```{r}

#dataValidation_origin <- readRDS("datasetValidationModeloClasificador.rds")
#dataValidation <- dataValidation_origin %>% dplyr::select(-SalePrice)


#remove <- c('GrupoPrecio')
#col_to_factor <- colnames(dataValidation) [! colnames(dataValidation) %in% remove]
#dataValidation <- dataValidation %>% as_factor_all(col_to_factor)


#XValidation <- dataValidation %>% dplyr::select(-GrupoPrecio)
#YValidation <- dataValidation$GrupoPrecio


```


```{r}

#pred <- predict(svm, newdata = XValidation)

#cm <- confusionMatrix(pred, YValidation, mode = "prec_recall" )
#(cm_pca)
#tab_test <- table(pred, YValidation, dnn = c("Actual", "Predichos"))
#draw_confusion_matrix(tab_test, "Actual", "Predichos")

```
